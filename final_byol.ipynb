{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BYOL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6DyGJVockAuZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ! gdown https://drive.google.com/uc?id=1oij5U35z8qe_cA1LNuDw882dQU1jWmC9\n",
        "# ! unzip histology-images-query-competition.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown https://drive.google.com/uc?id=1CBAM-L2j2qKLJ2jXGAMC4SD9ZMwIgZSo\n",
        "! gdown https://drive.google.com/uc?id=171edMp03GqaRb6jVyVCM6mUq30pOUPZG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv4CWwpaYAKS",
        "outputId": "5e1ece9a-4bb7-41d8-eeda-c5395f8adb70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CBAM-L2j2qKLJ2jXGAMC4SD9ZMwIgZSo\n",
            "To: /content/byol.py\n",
            "100% 7.97k/7.97k [00:00<00:00, 1.05MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=171edMp03GqaRb6jVyVCM6mUq30pOUPZG\n",
            "To: /content/validation_ground_truth.csv\n",
            "100% 5.22k/5.22k [00:00<00:00, 8.78MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install byol-pytorch"
      ],
      "metadata": {
        "id": "Qbn2WUmSkV5Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "\n",
        "from byol import BYOL\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "SkFT4tcNo77Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidDataSet(Dataset):\n",
        "    def __init__(self, images_folder_path, label_dic, transform=None):\n",
        "        self.images_folder_path = images_folder_path\n",
        "        self.label_dic = label_dic\n",
        "        if transform is not None:\n",
        "          self.transform=transform\n",
        "        else:\n",
        "          self.transform=transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_dic)\n",
        "    def __getitem__(self, index):\n",
        "        element = self.label_dic.iloc[index]\n",
        "        predic = element['prediction']\n",
        "        query = element['query']\n",
        "        img_name=query.split('_')\n",
        "        images=[]\n",
        "        # print(img_name)\n",
        "        for i in range(2):\n",
        "          images.append(PIL.Image.open(os.path.join(\n",
        "              self.images_folder_path, img_name[i]+'.png')))\n",
        "          images[i] = self.transform(images[i])\n",
        "          \n",
        "        return images[0],images[1], predic"
      ],
      "metadata": {
        "id": "OYEsGCAEq7T9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(PIL.ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "augmentation = [\n",
        "        transforms.RandomResizedCrop(256, scale=(0.2, 1.)),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "        ], p=0.8),\n",
        "        transforms.RandomGrayscale(p=0.2),\n",
        "        transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        "\n",
        "divide_transform=TwoCropsTransform(transforms.Compose(augmentation))\n",
        "transform=transforms.Compose(augmentation)"
      ],
      "metadata": {
        "id": "RqPFQuF5q0zN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "workers=2\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "        'train/',transform=divide_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,num_workers=workers, pin_memory=True, sampler=None, drop_last=True)\n",
        "\n",
        "\n",
        "valid_csv=pd.read_csv('validation_ground_truth.csv')\n",
        "valid_set=ValidDataSet('train/train',valid_csv,transform=transform)\n",
        "valid_loader=DataLoader(valid_set, batch_size=1, num_workers=workers, pin_memory=True)"
      ],
      "metadata": {
        "id": "1Zs2BDXSnkuo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "model = BYOL(\n",
        "    resnet,\n",
        "    image_size = 256,\n",
        "    hidden_layer = 'avgpool'\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n"
      ],
      "metadata": {
        "id": "Lu-qk-Enkglg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,print_freq):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "      data_time.update(time.time() - end)\n",
        "\n",
        "      # images[0] = images[0].to(device)\n",
        "      # images[1] = images[1].to(device)\n",
        "\n",
        "      loss = model([images[0].to(device),images[1].to(device)])\n",
        "      losses.update(loss.item(), images[0].size(0))\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      model.update_moving_average() # update moving average of target encoder\n",
        "\n",
        "      # measure elapsed time\n",
        "      batch_time.update(time.time() - end)\n",
        "      end = time.time()\n",
        "\n",
        "      if i % print_freq == 0:\n",
        "            progress.display(i)\n",
        "      torch.save(model.state_dict(), f'checkpoint_{epoch}.pth')\n",
        "    \n",
        "def valid(valid_loader,model,threshold):\n",
        "    # losses = AverageMeter('Loss', ':.4f')\n",
        "    # progress = ProgressMeter(\n",
        "    #     len(train_loader),\n",
        "    #     [losses],\n",
        "    #     prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    valid_loss=0\n",
        "    predict = [[0,0],[0,0]]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for images1,images2,labels in tqdm(valid_loader):\n",
        "          # images1 = images1.to(device)\n",
        "          # images2 = images2.to(device)\n",
        "          loss = model([images1.to(device),images2.to(device)])\n",
        "          # losses.update(loss.item(), images1.size(0))\n",
        "\n",
        "          # print(loss)\n",
        "          for i in range(len(labels)):\n",
        "            predict[labels[i]][loss<threshold]+=1\n",
        "            valid_loss+=loss if labels[i] else 1-loss\n",
        "      print(f'valid_loss:{valid_loss},predict:',predict)\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')"
      ],
      "metadata": {
        "id": "3KTbG4sdA-7Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epoches=10\n",
        "\n",
        "for epoch in range(epoches):\n",
        "    train(train_loader,model,opt,epoch,10)\n",
        "    valid(valid_loader,model,0.5)\n",
        "    save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer' : opt.state_dict(),\n",
        "            }, is_best=False, filename='checkpoint_{:04d}.pth.tar'.format(epoch))\n",
        "\n",
        "# save your improved network\n",
        "torch.save(resnet.state_dict(), './improved-net.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpFAQA4wop8v",
        "outputId": "c86c4a9f-d9eb-49f6-e017-69bc0bdb8a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/193]\tTime  4.405 ( 4.405)\tData  1.897 ( 1.897)\tLoss 3.8770 (3.8770)\n",
            "Epoch: [0][ 10/193]\tTime  3.443 ( 3.867)\tData  1.134 ( 1.538)\tLoss 1.7444 (2.0892)\n",
            "Epoch: [0][ 20/193]\tTime  9.184 ( 5.227)\tData  6.808 ( 2.880)\tLoss 1.7493 (1.9177)\n",
            "Epoch: [0][ 30/193]\tTime  9.434 ( 5.604)\tData  7.068 ( 3.251)\tLoss 1.7894 (1.8632)\n",
            "Epoch: [0][ 40/193]\tTime  3.717 ( 5.712)\tData  1.391 ( 3.354)\tLoss 1.7268 (1.8276)\n",
            "Epoch: [0][ 50/193]\tTime  6.374 ( 5.867)\tData  4.008 ( 3.507)\tLoss 1.5362 (1.7891)\n",
            "Epoch: [0][ 60/193]\tTime  7.411 ( 5.971)\tData  4.981 ( 3.608)\tLoss 1.4078 (1.7313)\n",
            "Epoch: [0][ 70/193]\tTime  6.211 ( 6.011)\tData  3.853 ( 3.649)\tLoss 1.2377 (1.6660)\n",
            "Epoch: [0][ 80/193]\tTime  6.777 ( 6.059)\tData  4.405 ( 3.695)\tLoss 0.7820 (1.5928)\n",
            "Epoch: [0][ 90/193]\tTime  6.630 ( 6.095)\tData  4.255 ( 3.731)\tLoss 0.8897 (1.5192)\n",
            "Epoch: [0][100/193]\tTime  6.306 ( 6.126)\tData  3.944 ( 3.761)\tLoss 0.9080 (1.4518)\n",
            "Epoch: [0][110/193]\tTime  7.170 ( 6.151)\tData  4.806 ( 3.785)\tLoss 0.6664 (1.3912)\n",
            "Epoch: [0][120/193]\tTime  6.448 ( 6.171)\tData  4.076 ( 3.804)\tLoss 0.6831 (1.3363)\n",
            "Epoch: [0][130/193]\tTime  6.323 ( 6.188)\tData  3.955 ( 3.821)\tLoss 0.5995 (1.2831)\n",
            "Epoch: [0][140/193]\tTime  6.326 ( 6.201)\tData  3.880 ( 3.833)\tLoss 0.6068 (1.2319)\n",
            "Epoch: [0][150/193]\tTime  5.828 ( 6.209)\tData  3.465 ( 3.842)\tLoss 0.3626 (1.1832)\n",
            "Epoch: [0][160/193]\tTime  6.625 ( 6.225)\tData  4.264 ( 3.857)\tLoss 0.5116 (1.1418)\n",
            "Epoch: [0][170/193]\tTime  6.271 ( 6.234)\tData  3.892 ( 3.866)\tLoss 0.3707 (1.1035)\n",
            "Epoch: [0][180/193]\tTime  6.548 ( 6.243)\tData  4.155 ( 3.874)\tLoss 0.3109 (1.0654)\n",
            "Epoch: [0][190/193]\tTime  6.772 ( 6.253)\tData  4.314 ( 3.883)\tLoss 0.4067 (1.0339)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:40<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid_loss:-200.47352600097656,predict: [[114, 0], [66, 6]]\n",
            "Epoch: [1][  0/193]\tTime  4.205 ( 4.205)\tData  1.716 ( 1.716)\tLoss 0.4759 (0.4759)\n",
            "Epoch: [1][ 10/193]\tTime  6.674 ( 4.521)\tData  4.221 ( 2.173)\tLoss 0.3498 (0.4484)\n",
            "Epoch: [1][ 20/193]\tTime  6.342 ( 5.399)\tData  3.980 ( 3.037)\tLoss 0.6454 (0.4496)\n",
            "Epoch: [1][ 30/193]\tTime  6.432 ( 5.721)\tData  4.078 ( 3.355)\tLoss 0.5402 (0.4313)\n",
            "Epoch: [1][ 40/193]\tTime  5.940 ( 5.872)\tData  3.568 ( 3.503)\tLoss 0.4410 (0.4373)\n",
            "Epoch: [1][ 50/193]\tTime  7.311 ( 5.988)\tData  4.925 ( 3.616)\tLoss 0.3243 (0.4252)\n",
            "Epoch: [1][ 60/193]\tTime  5.923 ( 6.047)\tData  3.557 ( 3.675)\tLoss 0.5708 (0.4169)\n",
            "Epoch: [1][ 70/193]\tTime  6.085 ( 6.094)\tData  3.626 ( 3.720)\tLoss 0.2387 (0.4101)\n",
            "Epoch: [1][ 80/193]\tTime  5.883 ( 6.127)\tData  3.509 ( 3.753)\tLoss 0.3604 (0.4076)\n"
          ]
        }
      ]
    }
  ]
}